{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhvOMqsyRH14"
      },
      "outputs": [],
      "source": [
        "''''\n",
        "mongodb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1.What are the key differences between SQL and NoSQL databases ?\n",
        "\n",
        "SQL Databases:\n",
        "Relational: Data is stored in tables (rows and columns), with a predefined schema.\n",
        "Schema-based: The structure must be defined in advance (e.g., data types, constraints).\n",
        "Examples: MySQL, PostgreSQL, Oracle.\n",
        "NoSQL Databases:\n",
        "Non-relational: Data can be stored in various forms such as key-value pairs, documents, graphs, or wide-column stores.\n",
        "Schema-less or Flexible Schema: Data structure can change over time without the need for restructuring the database.\n",
        "Examples: MongoDB, Cassandra, Redis, Neo4j."
      ],
      "metadata": {
        "id": "k4d6Vd3ERPBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q2. What makes MongoDB a good choice for modern applications ?\n",
        "\n",
        "MongoDB is a great choice for modern applications because of its:\n",
        "\n",
        "Flexible Schema – It stores data in a JSON-like format (BSON), allowing dynamic fields and easy schema evolution without complex migrations.\n",
        "\n",
        "High Scalability – Supports horizontal scaling using sharding, enabling applications to handle large volumes of data and traffic efficiently.\n",
        "\n",
        "Fast Performance – Uses indexing, in-memory storage, and optimized queries to ensure high-speed read and write operations.\n",
        "\n",
        "Cloud-Native & Distributed – Works seamlessly with cloud platforms (MongoDB Atlas), ensuring high availability, automatic backups, and easy scaling.\n",
        "\n",
        "This makes MongoDB perfect for real-time analytics, IoT, content management, and scalable web applications"
      ],
      "metadata": {
        "id": "ytnQhbP7RtF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q3. Explain the concept of collections in MongoDB.\n",
        "\n",
        "Collections in MongoDB\n",
        "\n",
        "In MongoDB, a collection is a group of documents, similar to a table in relational databases. However, unlike tables, collections in MongoDB:\n",
        "\n",
        "Do Not Have a Fixed Schema – Documents in a collection can have different fields, allowing flexibility.\n",
        "\n",
        "Store Data as BSON Documents – Each document is in JSON-like format, making it easy to store and retrieve data.\n",
        "\n",
        "Are Automatically Created – Collections are created when a document is inserted, without needing predefined structures."
      ],
      "metadata": {
        "id": "qxSNCiezR0pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q4. How does MongoDB ensure high availability using replication ?\n",
        "\n",
        "MongoDB ensures high availability using replication, specifically through Replica Sets. A Replica Set is a group of MongoDB instances that maintain the same data to provide redundancy and failover capabilities. Here's how it works:\n",
        "\n",
        "Primary-Secondary Architecture A Replica Set consists of: Primary Node: Handles all write and read operations (unless secondary reads are enabled). Secondary Nodes: Maintain copies of the primary’s data via replication. Arbiter (Optional): Helps in elections but does not store data.\n",
        "\n",
        "Automatic Failover If the primary node goes down, MongoDB automatically elects a new primary from the secondaries. The election process takes a few seconds (usually less than 12 seconds). Once a new primary is elected, applications can resume operations with minimal downtime.\n",
        "\n",
        "Data Redundancy and Synchronization The primary node continuously streams data changes to secondaries via oplogs (operations logs). Secondaries apply these operations in the same order to stay synchronized. If a secondary falls behind, it can perform rollback and resynchronization."
      ],
      "metadata": {
        "id": "yZBcnjAfR016"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q5. What are the main benefits of MongoDB Atlas ?\n",
        "\n",
        "MongoDB Atlas offers several key benefits, including:\n",
        "\n",
        "Fully Managed Service – It automates database deployment, scaling, and maintenance, reducing operational overhead.\n",
        "\n",
        "Scalability – Supports auto-scaling and sharding to handle growing workloads efficiently.\n",
        "\n",
        "High Availability – Provides built-in redundancy and failover with multi-region replication.\n",
        "\n",
        "Security – Features encryption, role-based access control (RBAC), and compliance with industry standards like GDPR and HIPAA.\n",
        "\n",
        "Performance Optimization – Includes automated performance monitoring, indexing suggestions, and workload optimization tools.\n",
        "\n",
        "Multi-Cloud Support – Allows deployment across AWS, Azure, or Google Cloud for flexibility and resilience."
      ],
      "metadata": {
        "id": "Cj4Q9X5rR04r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q6. What is the role of indexes in MongoDB, and how do they improve performance ?\n",
        "\n",
        "Role of Indexes in MongoDB:\n",
        "\n",
        "Indexes in MongoDB play a crucial role in improving query performance by enabling efficient data retrieval. Without indexes, MongoDB must scan every document in a collection to fulfill a query, which is slow for large datasets.\n",
        "\n",
        "How Indexes Improve Performance:\n",
        "\n",
        "Faster Query Execution – Indexes allow MongoDB to locate documents quickly without scanning the entire collection.\n",
        "\n",
        "Efficient Sorting – Queries with sort() perform better when indexed fields are used.\n",
        "\n",
        "Optimized Filtering – Queries with indexed fields reduce the number of documents MongoDB needs to inspect.\n",
        "\n",
        "Supports Unique Constraints – Unique indexes ensure data integrity by preventing duplicate values in a field.\n",
        "\n",
        "Improved Aggregation Performance – Indexes speed up aggregation pipelines by reducing the amount of data processed."
      ],
      "metadata": {
        "id": "ncZQ_eyRR07T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q7. Describe the stages of the MongoDB aggregation pipeline.\n",
        "\n",
        "The MongoDB aggregation pipeline processes data through multiple stages to transform and analyze documents efficiently. Key stages include:\n",
        "\n",
        "$match (filters documents)\n",
        "\n",
        "$group (aggregates data)\n",
        "\n",
        "$project (reshapes documents)\n",
        "\n",
        "$sort (orders results)\n",
        "\n",
        "$unwind (splits arrays into multiple documents)\n",
        "\n",
        "$lookup (performs joins)\n",
        "\n",
        "$out (writes results to a collection)\n",
        "\n",
        "$addFields (adds computed fields)\n",
        "\n",
        "These stages can be combined for powerful data processing and analytics."
      ],
      "metadata": {
        "id": "9SHStoBhR09r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q8. What is sharding in MongoDB? How does it differ from replication ?\n",
        "\n",
        "Sharding is a method of distributing data across multiple servers to handle large datasets and high throughput. It ensures horizontal scalability by partitioning data into smaller, more manageable pieces (shards).\n",
        "\n",
        "Uses a shard key to determine how data is distributed.\n",
        "\n",
        "Each shard stores only a subset of the data.\n",
        "\n",
        "A mongos router directs queries to the correct shard(s)."
      ],
      "metadata": {
        "id": "A7eoCwsNR1AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q9. What is PyMongo, and why is it used ?\n",
        "\n",
        "PyMongo is the official Python driver for MongoDB, allowing Python applications to interact with MongoDB databases. It provides an interface to perform CRUD operations (Create, Read, Update, Delete), run aggregation pipelines, and manage collections.\n",
        "\n",
        "Why is PyMongo Used?\n",
        "\n",
        "Database Connectivity – Enables Python applications to connect to MongoDB.\n",
        "\n",
        "Easy CRUD Operations – Simplifies inserting, querying, updating, and deleting documents.\n",
        "\n",
        "Aggregation Support – Allows running MongoDB aggregation pipelines.\n",
        "\n",
        "Index Management – Helps create and manage indexes for performance optimization.\n",
        "\n",
        "Scalability & Replication Support – Works with sharded clusters and replica sets."
      ],
      "metadata": {
        "id": "0lttpv6SR1CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q10. What are the ACID properties in the context of MongoDB transactions ?\n",
        "\n",
        "In the context of MongoDB transactions, the ACID properties ensure data integrity and consistency. ACID stands for:\n",
        "\n",
        "Atomicity: A transaction is treated as a single unit—either all operations within the transaction succeed, or none of them are applied. If an error occurs, MongoDB rolls back the transaction.\n",
        "\n",
        "Consistency: The database remains in a valid state before and after the transaction. Any changes made within a transaction must adhere to the schema and validation rules of the database.\n",
        "\n",
        "Isolation: Transactions execute independently, ensuring that intermediate changes are not visible to other operations until the transaction is committed. In MongoDB, transactions follow snapshot isolation, meaning they use a consistent view of the data when executing.\n",
        "\n",
        "Durability: Once a transaction is committed, changes are permanently saved in the database, even if there is a system crash or failure. MongoDB achieves this by writing data to the journal before confirming the commit."
      ],
      "metadata": {
        "id": "c66kbR-WR1Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q11. What is the purpose of MongoDB’s explain() function ?\n",
        "\n",
        "MongoDB’s explain() function is used to analyze how a query is executed, helping developers and database administrators optimize performance. It provides insights into how MongoDB processes a query by detailing aspects such as:\n",
        "\n",
        "Query Execution Plan: Shows whether an index was used, if a collection scan occurred, or how many documents were examined.\n",
        "\n",
        "Execution Time: Helps in understanding query efficiency by displaying the time taken for execution.\n",
        "\n",
        "Index Usage: Indicates whether an index was used and which one, aiding in performance tuning."
      ],
      "metadata": {
        "id": "HRJBX6vGR1G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q12. How does MongoDB handle schema validation ?\n",
        "\n",
        "Schema Validation in MongoDB\n",
        "\n",
        "MongoDB is a schema-less database, but it allows schema validation to enforce data integrity within collections. Schema validation is implemented using JSON Schema rules at the collection level.\n",
        "\n",
        "Key Features of Schema Validation:\n",
        "\n",
        "Ensures data consistency by defining rules for document structure.\n",
        "\n",
        "Applies validation rules at the time of insert and update operations.\n",
        "\n",
        "Uses BSON types (e.g., string, number, object, etc.)."
      ],
      "metadata": {
        "id": "QvITONk1R1JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q13. What is the difference between a primary and a secondary node in a replica set ?\n",
        "\n",
        "Primary Node:\n",
        "Role: The primary node is the main node that handles all write operations and is responsible for maintaining the definitive version of the data.\n",
        "Write Operations: All write operations (insert, update, delete) are directed to the primary node. It is the only node in the replica set that can accept writes.\n",
        "Replication: After a write operation is applied to the primary node, it gets replicated to the secondary nodes to maintain data consistency across the replica set.\n",
        "Election Process: If the current primary node becomes unavailable (due to failure, for example), the replica set will automatically initiate an election process to elect a new primary node from the secondary nodes.\n",
        "2. Secondary Node:\n",
        "Role: Secondary nodes are the backup nodes in the replica set. They replicate the data from the primary node, ensuring redundancy and high availability.\n",
        "Read Operations: Secondary nodes can handle read operations if configured to do so. However, by default, they don't handle write operations. In some setups, secondary nodes can be used for read scaling by using a feature like Read Preference in MongoDB, where certain queries are directed to secondary nodes to offload traffic from the primary.\n",
        "Replication: Secondary nodes maintain an up-to-date copy of the data by continuously replicating the operations performed on the primary node. They apply these changes in the same order in which they occur on the primary."
      ],
      "metadata": {
        "id": "NNEewWCdSTJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q14. What security mechanisms does MongoDB provide for data protection ?\n",
        "\n",
        "MongoDB Security Mechanisms\n",
        "\n",
        "Authentication – Verifies users using SCRAM, X.509, LDAP, or Kerberos.\n",
        "\n",
        "Authorization (RBAC) – Controls user permissions with role-based access control.\n",
        "\n",
        "TLS/SSL Encryption – Secures data in transit between clients and servers.\n",
        "\n",
        "Encryption at Rest – Protects stored data using WiredTiger encryption.\n",
        "\n",
        "Firewall & IP Whitelisting – Restricts database access to trusted IPs.\n",
        "\n",
        "Audit Logging – Tracks database events and user actions for security monitoring.\n",
        "\n",
        "Backup & Recovery – Ensures data protection using replication, snapshots, and backups."
      ],
      "metadata": {
        "id": "PztE5-_5STOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q15. Explain the concept of embedded documents and when they should be used.\n",
        "\n",
        "In MongoDB, embedded documents (also called nested documents) allow storing related data within a single document instead of using separate collections and references. This follows a denormalized approach, improving performance by reducing the need for joins.\n",
        "\n",
        "When to Use Embedded Documents?\n",
        "\n",
        "Use Embedded Documents When:\n",
        "\n",
        "One-to-Few Relationship – Example: A user profile with an embedded address or preferences.\n",
        "\n",
        "Data is Frequently Accessed Together – Example: Order details (products, price, shipping) inside an orders collection.\n",
        "\n",
        "No Need for Separate Queries – If you always fetch data together, embedding reduces the need for joins."
      ],
      "metadata": {
        "id": "GhXpDWmjSTRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q16. What is the purpose of MongoDB’s $lookup stage in aggregation ?\n",
        "\n",
        "Purpose of MongoDB’s $lookup Stage in Aggregation\n",
        "\n",
        "The $lookup stage in MongoDB’s aggregation pipeline performs a left outer join between two collections. It is used to retrieve related data from another collection and embed it in the query result.\n",
        "\n",
        "When to Use $lookup?\n",
        "\n",
        "Use $lookup when:\n",
        "\n",
        "You need to join two collections (similar to SQL joins).\n",
        "\n",
        "You want to avoid data duplication by keeping related data in separate collections.\n",
        "\n",
        "You need to retrieve additional details for a query result."
      ],
      "metadata": {
        "id": "Ty8nJv4jSTWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q17. What are some common use cases for MongoDB ?\n",
        "\n",
        "Common Use Cases for MongoDB\n",
        "\n",
        "Real-Time Analytics – Used in financial markets and website traffic monitoring.\n",
        "\n",
        "Content Management – Ideal for blogs, product catalogs, and news platforms.\n",
        "\n",
        "IoT & Sensor Data – Stores smart home and industrial sensor logs.\n",
        "\n",
        "E-Commerce – Manages product inventories, customer orders, and reviews.\n",
        "\n",
        "Gaming – Tracks player profiles, in-game purchases, and leaderboards.\n",
        "\n",
        "Social Media & Chat Apps – Handles messages, notifications, and user interactions.\n",
        "\n",
        "Geospatial Apps – Used in ride-hailing services and location tracking.\n",
        "\n",
        "Healthcare – Stores patient records and medical history securely"
      ],
      "metadata": {
        "id": "NX9iklH2STZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q18. What are the advantages of using MongoDB for horizontal scaling ?\n",
        "\n",
        "Advantages of Using MongoDB for Horizontal Scaling :\n",
        "\n",
        "Sharding – Distributes data across multiple servers, enabling scalability.\n",
        "\n",
        "Automatic Data Distribution – Handles data balancing automatically across nodes.\n",
        "\n",
        "High Availability – Uses replica sets for data redundancy and automatic failover.\n",
        "\n",
        "Easy to Scale Out – Simply add more servers to scale horizontally with no downtime.\n",
        "\n",
        "Efficient Data Handling – Handles large datasets and high-traffic applications.\n",
        "\n",
        "Flexible Schema – Easily adapts to changing data models as the app grows."
      ],
      "metadata": {
        "id": "th8TW3OMSTbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q19. How do MongoDB transactions differ from SQL transactions ?\n",
        "\n",
        "MongoDB transactions and SQL transactions differ in several ways, mainly due to their underlying database architectures. Here are the key differences:\n",
        "\n",
        "Data Model MongoDB: Uses a document-based NoSQL model where data is stored in JSON-like BSON documents. SQL Databases: Use a relational model with tables, rows, and columns.\n",
        "\n",
        "ACID Compliance MongoDB: Supports ACID transactions (since version 4.0) but is optimized for document-level operations. Multi-document transactions are available but can have performance overhead. SQL Databases: Designed with ACID compliance at their core, ensuring strong consistency across multiple tables and rows.\n",
        "\n",
        "Scope of Transactions MongoDB: Transactions are mainly used for multi-document operations within a single replica set or sharded cluster. SQL Databases: Transactions can span multiple tables, rows, and even databases.\n",
        "\n",
        "Performance Impact MongoDB: Since MongoDB is optimized for high-speed document-based operations, transactions introduce additional overhead, potentially reducing performance. SQL Databases: Transactions are natively integrated and optimized for handling multiple complex operations efficiently.\n",
        "\n",
        "Concurrency Control MongoDB: Uses an optimistic concurrency control approach, where operations typically retry on failure. SQL Databases: Use pessimistic locking with explicit row and table locks."
      ],
      "metadata": {
        "id": "y_d90VLySTeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q20. What are the main differences between capped collections and regular collections ?\n",
        "\n",
        "1.Capped collections in MongoDB are fixed-size and automatically overwrite the oldest documents when full, making them ideal for logging or time-series data. They support only the default _id index and do not allow updates or deletions (except for replacements). Their performance is optimized for high-throughput inserts and simple queries.\n",
        "\n",
        "2.Regular collections, on the other hand, are dynamic in size, allowing for full updates, deletions, and multiple indexes. They offer more flexibility but may incur more overhead in managing data and indexing. Regular collections are suitable for general-purpose data storage and complex querying."
      ],
      "metadata": {
        "id": "-3MUQx0iSThP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q21. What is the purpose of the $match stage in MongoDB’s aggregation pipeline ?\n",
        "\n",
        "Purpose of the $match Stage in MongoDB’s Aggregation Pipeline\n",
        "\n",
        "The $match stage is used to filter documents based on specified conditions, similar to the find() query but within the aggregation pipeline. It improves performance by reducing the number of documents processed in later stages.\n",
        "\n",
        "Key Features: Acts as a filter to include only relevant documents.\n",
        "\n",
        "Improves efficiency by reducing the dataset early in the pipeline."
      ],
      "metadata": {
        "id": "JshZsg5XSTjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q22. How can you secure access to a MongoDB database ?\n",
        "\n",
        "To secure a MongoDB database:\n",
        "\n",
        "Enable Authentication – Use username-password authentication (SCRAM-SHA-256).\n",
        "\n",
        "Role-Based Access Control (RBAC) – Assign minimal privileges using roles (read, readWrite).\n",
        "\n",
        "Enable TLS/SSL Encryption – Encrypt data in transit using SSL/TLS.\n",
        "\n",
        "Use IP Whitelisting – Restrict access to specific IPs using bindIp.\n",
        "\n",
        "Disable Remote Access – Run MongoDB on localhost unless external access is needed.\n",
        "\n",
        "Enable Firewall Rules – Use firewalls (UFW, IPTables) to block unauthorized access.\n",
        "\n",
        "Encrypt Data at Rest – Use WiredTiger encryption for stored data.\n",
        "\n",
        "Audit & Monitor – Enable logging and use monitoring tools (MongoDB Atlas, Prometheus)."
      ],
      "metadata": {
        "id": "2adtw6F8TlrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q23. What is MongoDB’s WiredTiger storage engine, and why is it important ?\n",
        "\n",
        "MongoDB’s WiredTiger Storage Engine and Its Importance\n",
        "\n",
        "WiredTiger is MongoDB’s default storage engine (since version 3.2), designed for high performance, concurrency, and efficient memory use.\n",
        "\n",
        "Key Features & Importance:\n",
        "\n",
        "Document-Level Concurrency – Supports multiple read/write operations simultaneously, improving performance.\n",
        "\n",
        "Compression – Uses Snappy, Zlib, or Zstd to reduce storage footprint.\n",
        "\n",
        "Journaling – Ensures data durability and crash recovery.\n",
        "\n",
        "Checkpointing – Reduces write amplification and speeds up recovery.\n",
        "\n",
        "Indexing Efficiency – Uses B-Trees for faster lookups."
      ],
      "metadata": {
        "id": "PjtDsdsOTlxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Practical Questions"
      ],
      "metadata": {
        "id": "v7tTkApzTl0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Write a Python script to load the Superstore dataset from a CSV file into MongoDB.\n",
        "\n",
        "import pandas as pd\n",
        "import pymongo\n",
        "\n",
        "# MongoDB connection details\n",
        "MONGO_URI = \"mongodb://localhost:27017/\"  # Change if needed\n",
        "DB_NAME = \"superstore_db\"\n",
        "COLLECTION_NAME = \"sales\"\n",
        "CSV_FILE_PATH = \"Superstore.csv\"  # Change to the actual path of your dataset\n",
        "\n",
        "# Establish connection to MongoDB\n",
        "client = pymongo.MongoClient(MONGO_URI)\n",
        "db = client[DB_NAME]\n",
        "collection = db[COLLECTION_NAME]\n",
        "\n",
        "# Load CSV data into a DataFrame with encoding handling\n",
        "try:\n",
        "    df = pd.read_csv(CSV_FILE_PATH, encoding=\"ISO-8859-1\")\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv(CSV_FILE_PATH, encoding=\"utf-8-sig\")\n",
        "\n",
        "# Convert DataFrame to dictionary format for MongoDB\n",
        "data = df.to_dict(orient=\"records\")\n",
        "\n",
        "# Insert data into MongoDB\n",
        "collection.insert_many(data)\n",
        "\n",
        "print(f\"Inserted {len(data)} records into MongoDB collection '{COLLECTION_NAME}'.\")"
      ],
      "metadata": {
        "id": "jwJoNtTtTzwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q2. Retrieve and print all documents from the Orders collection.\n",
        "\n",
        "import pandas as pd\n",
        "import pymongo\n",
        "from pprint import pprint\n",
        "\n",
        "# MongoDB connection details\n",
        "MONGO_URI = \"mongodb://localhost:27017/\"  # Change if needed\n",
        "DB_NAME = \"superstore_db\"\n",
        "COLLECTION_NAME = \"sales\"\n",
        "CSV_FILE_PATH = \"Superstore.csv\"  # Change to the actual path of your dataset\n",
        "\n",
        "# Establish connection to MongoDB\n",
        "client = pymongo.MongoClient(MONGO_URI)\n",
        "db = client[DB_NAME]\n",
        "collection = db[COLLECTION_NAME]\n",
        "\n",
        "# Load CSV data into a DataFrame with encoding handling\n",
        "try:\n",
        "    df = pd.read_csv(CSV_FILE_PATH, encoding=\"ISO-8859-1\")\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv(CSV_FILE_PATH, encoding=\"utf-8-sig\")\n",
        "\n",
        "# Convert DataFrame to dictionary format for MongoDB\n",
        "data = df.to_dict(orient=\"records\")\n",
        "\n",
        "# Insert data into MongoDB\n",
        "collection.insert_many(data)\n",
        "\n",
        "print(f\"Inserted {len(data)} records into MongoDB collection '{COLLECTION_NAME}'.\")\n",
        "\n",
        "# Retrieve and print all documents from the Orders collection\n",
        "orders_collection = db[\"Orders\"]\n",
        "all_orders = list(orders_collection.find())\n",
        "\n",
        "if all_orders:\n",
        "    print(\"Orders Collection Documents:\")\n",
        "    for order in all_orders:\n",
        "        pprint(order)\n",
        "else:\n",
        "    print(\"No documents found in the Orders collection.\")"
      ],
      "metadata": {
        "id": "N8etvZ9vTzzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q3. Count and display the total number of documents in the Orders collection.\n",
        "\n",
        "import pandas as pd\n",
        "import pymongo\n",
        "from pprint import pprint\n",
        "\n",
        "# MongoDB connection details\n",
        "MONGO_URI = \"mongodb://localhost:27017/\"  # Change if needed\n",
        "DB_NAME = \"superstore_db\"\n",
        "COLLECTION_NAME = \"sales\"\n",
        "CSV_FILE_PATH = \"Superstore.csv\"  # Change to the actual path of your dataset\n",
        "\n",
        "# Establish connection to MongoDB\n",
        "client = pymongo.MongoClient(MONGO_URI)\n",
        "db = client[DB_NAME]\n",
        "collection = db[COLLECTION_NAME]\n",
        "\n",
        "# Load CSV data into a DataFrame with encoding handling\n",
        "try:\n",
        "    df = pd.read_csv(CSV_FILE_PATH, encoding=\"ISO-8859-1\")\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv(CSV_FILE_PATH, encoding=\"utf-8-sig\")\n",
        "\n",
        "# Convert DataFrame to dictionary format for MongoDB\n",
        "data = df.to_dict(orient=\"records\")\n",
        "\n",
        "# Insert data into MongoDB\n",
        "collection.insert_many(data)\n",
        "\n",
        "print(f\"Inserted {len(data)} records into MongoDB collection '{COLLECTION_NAME}'.\")\n",
        "\n",
        "# Retrieve and print all documents from the Orders collection\n",
        "orders_collection = db[\"Orders\"]\n",
        "all_orders = list(orders_collection.find())\n",
        "\n",
        "if all_orders:\n",
        "    print(\"Orders Collection Documents:\")\n",
        "    for order in all_orders:\n",
        "        pprint(order)\n",
        "else:\n",
        "    print(\"No documents found in the Orders collection.\")\n",
        "\n",
        "# Count and display the total number of documents in the Orders collection\n",
        "total_orders = orders_collection.count_documents({})\n",
        "print(f\"Total number of documents in the Orders collection: {total_orders}\")"
      ],
      "metadata": {
        "id": "Pm7L16rzTz1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q4. Write a query to fetch all orders from the \"West\" region.\n",
        "\n",
        "import pandas as pd\n",
        "import pymongo\n",
        "from pprint import pprint\n",
        "\n",
        "# MongoDB connection details\n",
        "MONGO_URI = \"mongodb://localhost:27017/\"  # Change if needed\n",
        "DB_NAME = \"superstore_db\"\n",
        "COLLECTION_NAME = \"sales\"\n",
        "CSV_FILE_PATH = \"Superstore.csv\"  # Change to the actual path of your dataset\n",
        "\n",
        "# Establish connection to MongoDB\n",
        "client = pymongo.MongoClient(MONGO_URI)\n",
        "db = client[DB_NAME]\n",
        "collection = db[COLLECTION_NAME]\n",
        "\n",
        "# Load CSV data into a DataFrame with encoding handling\n",
        "try:\n",
        "    df = pd.read_csv(CSV_FILE_PATH, encoding=\"ISO-8859-1\")\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv(CSV_FILE_PATH, encoding=\"utf-8-sig\")\n",
        "\n",
        "# Convert DataFrame to dictionary format for MongoDB\n",
        "data = df.to_dict(orient=\"records\")\n",
        "\n",
        "# Insert data into MongoDB\n",
        "collection.insert_many(data)\n",
        "\n",
        "print(f\"Inserted {len(data)} records into MongoDB collection '{COLLECTION_NAME}'.\")\n",
        "\n",
        "# Retrieve and print all documents from the Orders collection\n",
        "orders_collection = db[\"Orders\"]\n",
        "all_orders = list(orders_collection.find())\n",
        "\n",
        "if all_orders:\n",
        "    print(\"Orders Collection Documents:\")\n",
        "    for order in all_orders:\n",
        "        pprint(order)\n",
        "else:\n",
        "    print(\"No documents found in the Orders collection.\")\n",
        "\n",
        "# Count and display the total number of documents in the Orders collection\n",
        "total_orders = orders_collection.count_documents({})\n",
        "print(f\"Total number of documents in the Orders collection: {total_orders}\")\n",
        "\n",
        "# Fetch and print all orders from the 'West' region\n",
        "west_orders = list(orders_collection.find({\"Region\": \"West\"}))\n",
        "print(\"Orders from the West region:\")\n",
        "for order in west_orders:\n",
        "    pprint(order)"
      ],
      "metadata": {
        "id": "4W3ZdTNsTz38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q5. Write a query to find orders where Sales is greater than 500.\n",
        "\n",
        "# Fetch and print all orders where Sales is greater than 500\n",
        "high_sales_orders = list(orders_collection.find({\"Sales\": {\"$gt\": 500}}))\n",
        "print(\"Orders where Sales is greater than 500:\")\n",
        "for order in high_sales_orders:\n",
        "    pprint(order)"
      ],
      "metadata": {
        "id": "Uf39j7cFTz6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q6. Fetch the top 3 orders with the highest Profit.\n",
        "\n",
        "# Fetch and print the top 3 orders with the highest Profit\n",
        "top_profit_orders = list(orders_collection.find().sort(\"Profit\", -1).limit(3))\n",
        "print(\"Top 3 orders with the highest Profit:\")\n",
        "for order in top_profit_orders:\n",
        "    pprint(order)"
      ],
      "metadata": {
        "id": "PFjB1D4PTz8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q7. Update all orders with Ship Mode as \"First Class\" to \"Premium Class.\n",
        "\n",
        "# Update all orders with Ship Mode as \"First Class\" to \"Premium Class\"\n",
        "update_result = orders_collection.update_many(\n",
        "    {\"Ship Mode\": \"First Class\"},\n",
        "    {\"$set\": {\"Ship Mode\": \"Premium Class\"}}\n",
        ")\n",
        "print(f\"Updated {update_result.modified_count} documents where Ship Mode was 'First Class'.\")"
      ],
      "metadata": {
        "id": "kO1lWhOlTz-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q8. Delete all orders where Sales is less than 50.\n",
        "\n",
        "# Delete all orders where Sales is less than 50\n",
        "delete_result = orders_collection.delete_many({\"Sales\": {\"$lt\": 50}})\n",
        "print(f\"Deleted {delete_result.deleted_count} documents where Sales was less than 50.\")"
      ],
      "metadata": {
        "id": "Iwd1UqO2VPAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q9.Use aggregation to group orders by Region and calculate total sales per region.\n",
        "\n",
        "# Use aggregation to group orders by Region and calculate total sales per region\n",
        "region_sales = list(orders_collection.aggregate([\n",
        "    {\"$group\": {\"_id\": \"$Region\", \"TotalSales\": {\"$sum\": \"$Sales\"}}}\n",
        "]))\n",
        "\n",
        "print(\"Total Sales per Region:\")\n",
        "for region in region_sales:\n",
        "    pprint(region)"
      ],
      "metadata": {
        "id": "XfcZMgTaVPFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q10. Fetch all distinct values for Ship Mode from the collection.\n",
        "\n",
        "# Fetch all distinct values for Ship Mode\n",
        "distinct_ship_modes = orders_collection.distinct(\"Ship Mode\")\n",
        "print(\"Distinct Ship Modes:\")\n",
        "pprint(distinct_ship_modes)"
      ],
      "metadata": {
        "id": "0wmYetTTVgwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q11. Count the number of orders for each category.\n",
        "\n",
        "# Count the number of orders for each category\n",
        "category_orders = list(orders_collection.aggregate([\n",
        "    {\"$group\": {\"_id\": \"$Category\", \"TotalOrders\": {\"$sum\": 1}}}\n",
        "]))\n",
        "\n",
        "print(\"Total Orders per Category:\")\n",
        "for category in category_orders:\n",
        "    pprint(category)"
      ],
      "metadata": {
        "id": "wwNwBKxuV2UW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}